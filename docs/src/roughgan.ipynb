{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11180fd8",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/billsioros/RoughML\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58367bfb",
   "metadata": {
    "id": "cce26209"
   },
   "source": [
    "# ✔️ Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc4513",
   "metadata": {
    "id": "affab565"
   },
   "source": [
    "First of all we need to take care of a few **prerequisites**, most notably:\n",
    "\n",
    "- Install the various pip modules that we will be using.\n",
    "- Install some linux specific dependencies of our [content loss](#content-loss).\n",
    "- Initialize the Random Number Generator(s), so that our experiments can be replicated.\n",
    "- Determine:\n",
    "  - The current working directory, as it's going to be used to reference various files such as the dataset, our model checkpoints e.t.c\n",
    "  - The available hardware backend. GPU utilization is preferable, as it results in higher complition time.\n",
    "- `(Optionally)` Mount Google Drive, where we can load our dataset from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94211220",
   "metadata": {
    "id": "19e0a6d0"
   },
   "source": [
    "## Determining the Current Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ebc9f",
   "metadata": {
    "cellView": "code",
    "id": "945a9ccd"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58002fe",
   "metadata": {
    "id": "94c4d99f"
   },
   "source": [
    "## Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4f9f9",
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e24f0051",
    "outputId": "30ae6242-7890-45fb-97f4-7a3f98101b5c"
   },
   "outputs": [],
   "source": [
    "GDRIVE_DIR = BASE_DIR / \"drive\"\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(f\"{GDRIVE_DIR}\")\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68548e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SECRETS_DIR = GDRIVE_DIR / \"MyDrive\" / \"Secrets\"\n",
    "\n",
    "if GDRIVE_DIR.is_dir():\n",
    "    THESIS_DIR = GDRIVE_DIR / \"MyDrive\" / \"Thesis\"\n",
    "else:\n",
    "    THESIS_DIR = BASE_DIR\n",
    "\n",
    "OUTPUT_DIR = THESIS_DIR / \"Output\"\n",
    "\n",
    "if THESIS_DIR.is_dir():\n",
    "    DATASET_DIR = THESIS_DIR / \"Datasets\"\n",
    "else:\n",
    "    DATASET_DIR = BASE_DIR / \"Datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00abe820",
   "metadata": {},
   "source": [
    "## Configuring our Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206c8800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "LOGGING_LEVEL = os.environ.get(\"LOGGING_LEVEL\", \"CRITICAL\").upper()\n",
    "\n",
    "LOGGING_CONFIG = {\n",
    "    \"version\": 1,\n",
    "    \"disable_existing_loggers\": False,\n",
    "    \"formatters\": {\"standard\": {\"format\": \"[%(asctime)s] %(levelname)s:%(name)s: %(message)s\"}},\n",
    "    \"handlers\": {\n",
    "        \"default\": {\n",
    "            \"level\": LOGGING_LEVEL,\n",
    "            \"formatter\": \"standard\",\n",
    "            \"class\": \"logging.StreamHandler\",\n",
    "        },\n",
    "        \"file\": {\n",
    "            \"level\": LOGGING_LEVEL,\n",
    "            \"formatter\": \"standard\",\n",
    "            \"class\": \"logging.FileHandler\",\n",
    "        },\n",
    "    },\n",
    "    \"loggers\": {\"\": {\"handlers\": [\"default\", \"file\"], \"level\": LOGGING_LEVEL}},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b52a5f8",
   "metadata": {
    "id": "16a902e2"
   },
   "source": [
    "## Installing [graphviz](https://graphviz.org/) & [libgraphviz-dev](https://packages.debian.org/jessie/libgraphviz-dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f505f148",
   "metadata": {
    "id": "8c0cdd85"
   },
   "source": [
    "The aforementioned packages are required by [PyINSECT](https://github.com/billsioros/PyINSECT/tree/implementing-HPGs) and more specifically its graph plotting methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075778c1",
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "919734ca",
    "outputId": "0767e6fd-b55e-4ebc-9e0e-11b243700c1c"
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install graphviz libgraphviz-dev 1> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84382a01",
   "metadata": {
    "id": "7f5668f4"
   },
   "source": [
    "## Installing the required `pip` modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5f3570",
   "metadata": {
    "id": "aebad6f1"
   },
   "source": [
    "- [torch](https://pytorch.org/) is our machine learning framework of choice.\n",
    "- [numpy](https://numpy.org/), [sympy](https://www.sympy.org/en/index.html) and [scipy](https://www.scipy.org/) are used to in the context of nanorough surface generation.\n",
    "- [plotly](https://plotly.com/) (which requires [pandas](https://pandas.pydata.org/)) as well as [matplotlib](https://matplotlib.org/) are used in order to plot various graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8129b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHEEL_VERSION = \"3.0.1\"\n",
    "WHEEL_FILE = \"roughgan-%s-py3-none-any.whl\" % (WHEEL_VERSION,)\n",
    "WHEEL_PATH = THESIS_DIR / \"Binaries\" / WHEEL_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ac2f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5ca41",
   "metadata": {
    "cellView": "code",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1057687b",
    "outputId": "2ab1f525-0235-4308-cabb-a7793277473b"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pip_freeze_output = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"freeze\"]).decode()\n",
    "\n",
    "if \"roughgan\" not in pip_freeze_output:\n",
    "    if WHEEL_PATH.is_file():\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", WHEEL_PATH])\n",
    "    else:\n",
    "        raise FileNotFoundError(WHEEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83d804",
   "metadata": {
    "id": "0192c059",
    "lines_to_next_cell": 0
   },
   "source": [
    "## Initializing (a.k.a `Seeding`) the Random Number Generator(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5013c17",
   "metadata": {
    "cellView": "code",
    "id": "4d6c30c9"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "if SEED is not None:\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf07155",
   "metadata": {
    "id": "6fce8a2a"
   },
   "source": [
    "## Determining available backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129dfa8e",
   "metadata": {
    "id": "5ca328f8"
   },
   "source": [
    "By default, we are going to be utilizing the available CPU backend, if no GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bf70f5",
   "metadata": {
    "cellView": "code",
    "id": "520ba5c1",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800dc08",
   "metadata": {},
   "source": [
    "## Setting up our callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a006d71",
   "metadata": {},
   "source": [
    "### End-of-training callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407ead0",
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from roughgan.shared.notifiers import EndOfTrainingNotifier\n",
    "\n",
    "training_callback = None\n",
    "if SECRETS_DIR.is_dir():\n",
    "    notifier = EndOfTrainingNotifier.from_json(SECRETS_DIR / \"credentials.json\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S.%f\")\n",
    "\n",
    "    def training_callback(log_file=None, **context):\n",
    "        notifier(\n",
    "            (\"Vasilis Sioros\", \"billsioros97@gmail.com\"),\n",
    "            log_file=log_file,\n",
    "            dataset=context[\"dataset\"],\n",
    "            generator=context[\"generator\"],\n",
    "            discriminator=context[\"discriminator\"],\n",
    "            elapsed_time=context[\"elapsed_time\"],\n",
    "            succeeded=context[\"succeeded\"],\n",
    "            identifier=timestamp,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e33c933",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Logging initialization callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb2d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_callback(config, logging_dir):\n",
    "    level = config.handlers.file.level.lower()\n",
    "\n",
    "    config.handlers.file.filename = logging_dir / f\"{level}.log\"\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e74de6",
   "metadata": {
    "id": "60d78d1e"
   },
   "source": [
    "# 🙃 A naive-approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e082998",
   "metadata": {
    "id": "ec374650"
   },
   "source": [
    "## Defining the **Generator** and the **Discriminator** instantiation callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56324ee9",
   "metadata": {
    "cellView": "code",
    "id": "d6594cb1"
   },
   "outputs": [],
   "source": [
    "from roughgan.models import PerceptronGenerator\n",
    "\n",
    "\n",
    "def get_generator():\n",
    "    return PerceptronGenerator.from_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a7f8e6",
   "metadata": {
    "cellView": "code",
    "id": "cac059ee"
   },
   "outputs": [],
   "source": [
    "from roughgan.models import PerceptronDiscriminator\n",
    "\n",
    "\n",
    "def get_discriminator(generator):\n",
    "    return PerceptronDiscriminator.from_generator(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c839b09",
   "metadata": {
    "id": "eb813599"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0fc5e",
   "metadata": {
    "cellView": "code",
    "id": "8a131c21"
   },
   "outputs": [],
   "source": [
    "from torch.nn import BCELoss\n",
    "\n",
    "criterion = BCELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f2a23",
   "metadata": {
    "cellView": "code",
    "id": "63114157"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "from roughgan.content.loss import NGramGraphContentLoss\n",
    "from roughgan.data.loaders import load_multiple_datasets_from_pt\n",
    "from roughgan.data.transforms import To, View\n",
    "from roughgan.training.epoch import per_epoch\n",
    "from roughgan.training.flow import TrainingFlow\n",
    "\n",
    "training_flow = TrainingFlow(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    logging={\"config\": LOGGING_CONFIG, \"callback\": logging_callback},\n",
    "    training={\n",
    "        \"manager\": {\n",
    "            \"benchmark\": True,\n",
    "            # Uncomment if you want to enable checkpointing\n",
    "            # \"checkpoint\": {\"multiple\": True},\n",
    "            \"train_epoch\": per_epoch,\n",
    "            \"log_every_n\": 10,\n",
    "            \"criterion\": {\"instance\": criterion},\n",
    "            \"n_epochs\": 10,\n",
    "            \"train_ratio\": 0.8,\n",
    "            \"optimizer\": {\n",
    "                \"type\": Adam,\n",
    "                \"params\": {\"lr\": 0.1, \"weight_decay\": 0},\n",
    "            },\n",
    "            \"dataloader\": {\n",
    "                \"batch_size\": 256,\n",
    "                \"shuffle\": True,\n",
    "                \"num_workers\": 0,\n",
    "            },\n",
    "        },\n",
    "        \"callbacks\": [\n",
    "            training_callback,\n",
    "        ],\n",
    "    },\n",
    "    content_loss={\n",
    "        \"type\": NGramGraphContentLoss,\n",
    "        # Uncomment if you want to enable checkpointing\n",
    "        # \"cache\": \"n_gram_graph_content_loss.pkl\",\n",
    "    },\n",
    "    data={\n",
    "        \"loader\": functools.partial(\n",
    "            load_multiple_datasets_from_pt,\n",
    "            DATASET_DIR,\n",
    "            transforms=[To(device), View(1, 128, 128)],\n",
    "            limit=(2, 10),\n",
    "        )\n",
    "    },\n",
    "    animation={\n",
    "        \"indices\": [\n",
    "            0,\n",
    "        ],\n",
    "        \"save_path\": \"perceptron_per_epoch_animation.mp4\",\n",
    "    },\n",
    "    plot={\n",
    "        \"grayscale\": {\"limit\": 10, \"save_path_fmt\": \"grayscale/%s_%02d.png\"},\n",
    "        \"surface\": {\"limit\": 10, \"save_path_fmt\": \"surface/%s_%02d.png\"},\n",
    "        \"against\": {\"save_path_fmt\": \"against_%s.png\"},\n",
    "    },\n",
    "    suppress_exceptions=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ea568",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "836ed418",
    "outputId": "f4d7ef3c-027c-4725-9f07-50e4d7c28ff1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_flow(get_generator, get_discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d20a8c",
   "metadata": {
    "id": "fe589c1a"
   },
   "source": [
    "# 😎 A CNN based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdbab9c",
   "metadata": {
    "id": "b16a4946"
   },
   "source": [
    "## Instantiating the **Generator** and the **Discriminator** Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823e0ae2",
   "metadata": {
    "cellView": "code",
    "id": "e301a7a0"
   },
   "outputs": [],
   "source": [
    "from roughgan.models import CNNGenerator\n",
    "\n",
    "\n",
    "def get_generator():\n",
    "    return CNNGenerator.from_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65bc1b8",
   "metadata": {
    "cellView": "code",
    "id": "5a8a9aad"
   },
   "outputs": [],
   "source": [
    "from roughgan.models import CNNDiscriminator\n",
    "\n",
    "\n",
    "def get_discriminator(generator):\n",
    "    return CNNDiscriminator.from_generator(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9fd6e4",
   "metadata": {
    "id": "7bbbcc22"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4febf2a4",
   "metadata": {
    "cellView": "code",
    "id": "45778b4c"
   },
   "outputs": [],
   "source": [
    "from torch.nn import BCELoss\n",
    "\n",
    "criterion = BCELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad01665",
   "metadata": {
    "cellView": "code",
    "id": "82fb12f6"
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "from roughgan.data.transforms import To, View\n",
    "from roughgan.training.epoch import per_epoch\n",
    "\n",
    "training_flow = TrainingFlow(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    logging={\"config\": LOGGING_CONFIG, \"callback\": logging_callback},\n",
    "    training={\n",
    "        \"manager\": {\n",
    "            \"benchmark\": True,\n",
    "            # Uncomment if you want to enable checkpointing\n",
    "            # \"checkpoint\": {\"multiple\": True},\n",
    "            \"train_epoch\": per_epoch,\n",
    "            \"log_every_n\": 10,\n",
    "            \"criterion\": {\"instance\": criterion},\n",
    "            \"n_epochs\": 10,\n",
    "            \"train_ratio\": 0.8,\n",
    "            \"optimizer\": {\n",
    "                \"type\": Adam,\n",
    "                \"params\": {\"lr\": 0.0002, \"betas\": (0.5, 0.999)},\n",
    "            },\n",
    "            \"dataloader\": {\n",
    "                \"batch_size\": 256,\n",
    "                \"shuffle\": True,\n",
    "                \"num_workers\": 0,\n",
    "            },\n",
    "        },\n",
    "        \"callbacks\": [\n",
    "            training_callback,\n",
    "        ],\n",
    "    },\n",
    "    content_loss={\n",
    "        \"type\": NGramGraphContentLoss,\n",
    "        # Uncomment if you want to enable checkpointing\n",
    "        # \"cache\": \"n_gram_graph_content_loss.pkl\",\n",
    "    },\n",
    "    data={\n",
    "        \"loader\": functools.partial(\n",
    "            load_multiple_datasets_from_pt,\n",
    "            DATASET_DIR,\n",
    "            transforms=[To(device), View(1, 128, 128)],\n",
    "            limit=(2, 10),\n",
    "        )\n",
    "    },\n",
    "    animation={\n",
    "        \"indices\": [\n",
    "            0,\n",
    "        ],\n",
    "        \"save_path\": \"cnn_per_epoch_animation.mp4\",\n",
    "    },\n",
    "    plot={\n",
    "        \"grayscale\": {\"limit\": 10, \"save_path_fmt\": \"grayscale/%s_%02d.png\"},\n",
    "        \"surface\": {\"limit\": 10, \"save_path_fmt\": \"surface/%s_%02d.png\"},\n",
    "        \"against\": {\"save_path_fmt\": \"against_%s.png\"},\n",
    "    },\n",
    "    suppress_exceptions=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5778a1a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "3c4cdce1",
    "outputId": "c22dfcc0-c6d9-4726-c197-acf11bdec52f"
   },
   "outputs": [],
   "source": [
    "training_flow(get_generator, get_discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b536a8",
   "metadata": {},
   "source": [
    "# 👋 Dismounting Google Drive and persisting any changes made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.flush_and_unmount()\n",
    "except ImportError:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "",
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
