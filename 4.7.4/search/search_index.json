{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"RoughGAN <p>Accompanying code for the paper Generating Realistic Nanorough Surfaces Using an N-Gram-Graph Augmented Deep Convolutional Generative Adversarial Network presented at SETN 2022.</p> <p>In this work, we look at how a Generative Adversarial Network (GAN)-based strategy, given a nanorough surface data set, may learn to produce nanorough surface samples that are statistically equivalent to the ones belonging to the training data set. We also look at how combining the GAN framework with a variety of nanorough similarity measures might improve the realisticity of the synthesized nanorough surfaces. We showcase via multiple experiments that our framework is able to produce sufficiently realistic nanorough surfaces, in many cases indistinguishable from real ones.</p>"},{"location":"#getting-started","title":"Getting started","text":"<p>You can run the model locally using the following commands:</p> <pre><code>docker build . -t roughgan:$( git tag -l | tail -1 | cut -c2- ) -t build:train -f Dockerfile\ndocker run -v $(pwd)/data:/home/app/app/data -v $(pwd)/models:/home/app/app/models --gpus $(nvidia-smi --list-gpus | wc -l) roughgan:latest\n</code></pre> <p>The project's documentation can be found here.</p>"},{"location":"#support-the-project","title":"Support the project","text":"<p>If you would like to contribute to the project, please go through the Contributing Guidelines first. You can also support the project by Buying me a coffee! \u2615.</p>"},{"location":"#citation","title":"Citation","text":"<pre><code>@inproceedings{10.1145/3549737.3549794,\nauthor = {Sioros, Vasilis and Giannakopoulos, George and Constantoudis, Vassileios},\ntitle = {Generating Realistic Nanorough Surfaces Using an N-Gram-Graph Augmented Deep Convolutional Generative Adversarial Network},\nyear = {2022},\nisbn = {9781450395977},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3549737.3549794},\ndoi = {10.1145/3549737.3549794},\nbooktitle = {Proceedings of the 12th Hellenic Conference on Artificial Intelligence},\narticleno = {53},\nnumpages = {10},\nkeywords = {Machine Learning, Rough Surfaces, Graph Theory, Nanotechnology, Artificial Intelligence},\nlocation = {Corfu, Greece},\nseries = {SETN '22}\n}\n</code></pre> <p>This project was generated using the <code>billsioros/cookiecutter-pypackage</code> cookiecutter template.</p>"},{"location":"CHANGELOG/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>This project adheres to Semantic Versioning. See Conventional Commits for commit guidelines.</p>"},{"location":"CHANGELOG/#v474-2023-07-11","title":"v4.7.4 (2023-07-11)","text":""},{"location":"CHANGELOG/#fix","title":"Fix","text":"<ul> <li>Set <code>torch</code> to <code>v1.9.0</code> (<code>2b096c2</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v473-2023-07-11","title":"v4.7.3 (2023-07-11)","text":""},{"location":"CHANGELOG/#fix_1","title":"Fix","text":"<ul> <li>deps: Update dependency torch to v1.13.1 [security] (<code>ed17d10</code>)</li> </ul>"},{"location":"CHANGELOG/#documentation","title":"Documentation","text":"<ul> <li>Update the <code>README</code> (<code>0dfca14</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v472-2023-07-11","title":"v4.7.2 (2023-07-11)","text":""},{"location":"CHANGELOG/#fix_2","title":"Fix","text":"<ul> <li>Frozen dependencies (<code>e0b53df</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v471-2023-07-11","title":"v4.7.1 (2023-07-11)","text":""},{"location":"CHANGELOG/#fix_3","title":"Fix","text":"<ul> <li>deps: Update dependency torch to v1.13.1 [security] (<code>7d34b13</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#changelog_1","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"CHANGELOG/#v474-2023-07-11_1","title":"v4.7.4 (2023-07-11)","text":""},{"location":"CHANGELOG/#fix_4","title":"Fix","text":"<ul> <li>Set <code>torch</code> to <code>v1.9.0</code> (<code>2b096c2</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v473-2023-07-11_1","title":"v4.7.3 (2023-07-11)","text":""},{"location":"CHANGELOG/#fix_5","title":"Fix","text":"<ul> <li>deps: Update dependency torch to v1.13.1 [security] (<code>ed17d10</code>)</li> </ul>"},{"location":"CHANGELOG/#documentation_1","title":"Documentation","text":"<ul> <li>Update the <code>README</code> (<code>0dfca14</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v472-2023-07-11_1","title":"v4.7.2 (2023-07-11)","text":""},{"location":"CHANGELOG/#fix_6","title":"Fix","text":"<ul> <li>Frozen dependencies (<code>e0b53df</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v471-2023-07-11_1","title":"v4.7.1 (2023-07-11)","text":""},{"location":"CHANGELOG/#fix_7","title":"Fix","text":"<ul> <li>deps: Update dependency torch to v1.13.1 [security] (<code>7d34b13</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v470-2022-02-13","title":"v4.7.0 (2022-02-13)","text":""},{"location":"CHANGELOG/#feature","title":"Feature","text":"<ul> <li>flow: Add latest epoch checkpoint (<code>87884b7</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v460-2021-10-19","title":"v4.6.0 (2021-10-19)","text":""},{"location":"CHANGELOG/#feature_1","title":"Feature","text":"<ul> <li>cli: <code>benchmark</code> content similarity script (<code>add2ad9</code>)</li> </ul>"},{"location":"CHANGELOG/#fix_8","title":"Fix","text":"<ul> <li>train: <code>content_loss.type</code> null check (<code>767616b</code>)</li> <li>loss: Suppress <code>.numpy()</code> AttributeError (<code>db2ef70</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v451-2021-10-09","title":"v4.5.1 (2021-10-09)","text":""},{"location":"CHANGELOG/#fix_9","title":"Fix","text":"<ul> <li>perceptron: Remove ReLU (<code>d20ed22</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v450-2021-09-30","title":"v4.5.0 (2021-09-30)","text":""},{"location":"CHANGELOG/#feature_2","title":"Feature","text":"<ul> <li>train: Generate per epoch data csv (<code>c154585</code>)</li> </ul>"},{"location":"CHANGELOG/#fix_10","title":"Fix","text":"<ul> <li>plot: Do not close plot on Windows (<code>ee82ad8</code>)</li> <li>loss: <code>VectorSpaceContentLoss</code> expects numpy matrix (<code>5d3acf8</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v440-2021-09-29","title":"v4.4.0 (2021-09-29)","text":""},{"location":"CHANGELOG/#feature_3","title":"Feature","text":"<ul> <li>loss: Normalize <code>VectorSpaceContentLoss</code> (<code>430ac52</code>)</li> <li>train: Plot fourier/histogram based content loss (<code>22c038c</code>)</li> <li>dataset: Make dataset path optional on CLI (<code>4c9b2a9</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v430-2021-08-23","title":"v4.3.0 (2021-08-23)","text":""},{"location":"CHANGELOG/#feature_4","title":"Feature","text":"<ul> <li>Load model from <code>.pt</code> file (<code>6a07e1d</code>)</li> </ul>"},{"location":"CHANGELOG/#fix_11","title":"Fix","text":"<ul> <li>Skip surface quantization on <code>VectorSpapceContentLoss</code> (<code>54b3f21</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v422-2021-08-03","title":"v4.2.2 (2021-08-03)","text":""},{"location":"CHANGELOG/#fix_12","title":"Fix","text":"<ul> <li>Call absolute on vector based content loss <code>__call__</code> (<code>99fd205</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v421-2021-08-03","title":"v4.2.1 (2021-08-03)","text":""},{"location":"CHANGELOG/#fix_13","title":"Fix","text":"<ul> <li>Calculate the <code>fft</code> absolute value (<code>3478628</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v420-2021-08-03","title":"v4.2.0 (2021-08-03)","text":""},{"location":"CHANGELOG/#feature_5","title":"Feature","text":"<ul> <li>Introduce the <code>VectorSpaceContentLoss</code> (<code>20248b1</code>)</li> </ul>"},{"location":"CHANGELOG/#fix_14","title":"Fix","text":"<ul> <li>Remove latest <code>RELU</code> from CNN generator (<code>5797205</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v412-2021-07-27","title":"v4.1.2 (2021-07-27)","text":""},{"location":"CHANGELOG/#fix_15","title":"Fix","text":"<ul> <li>Use sane defaults in <code>dataset</code> CLI (<code>d79941a</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v411-2021-07-27","title":"v4.1.1 (2021-07-27)","text":""},{"location":"CHANGELOG/#fix_16","title":"Fix","text":"<ul> <li>Make <code>grayscale</code>/'3d' visualization full size (<code>8f01807</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v410-2021-07-27","title":"v4.1.0 (2021-07-27)","text":""},{"location":"CHANGELOG/#feature_6","title":"Feature","text":"<ul> <li>Implement the tuning flow (<code>81bf9c0</code>)</li> <li>Create a hyper parameter tuning CLI (<code>5f462d1</code>)</li> <li>Dataset generation script (<code>428b6fd</code>)</li> <li><code>cli</code>s aimed towards visualization and dataset generation (<code>692a1c0</code>)</li> </ul>"},{"location":"CHANGELOG/#fix_17","title":"Fix","text":"<ul> <li>Make tuning CLI available after installation (<code>1b90a34</code>)</li> <li>Show default logging level (<code>986b6ac</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v400-2021-07-18","title":"v4.0.0 (2021-07-18)","text":""},{"location":"CHANGELOG/#feature_7","title":"Feature","text":"<ul> <li>Add hyper parameter tuning interface (<code>d486372</code>)</li> <li>Make content loss optional (<code>75d9b0e</code>)</li> </ul>"},{"location":"CHANGELOG/#breaking","title":"Breaking","text":"<ul> <li>make optimizer a parameter to <code>TrainingManager</code> (<code>57f0dc8</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v310-2021-07-15","title":"v3.1.0 (2021-07-15)","text":""},{"location":"CHANGELOG/#feature_8","title":"Feature","text":"<ul> <li>Separately log/plot <code>content_loss</code> (<code>fc16be6</code>)</li> <li>Instantiate models per dataset (<code>f7bee53</code>)</li> <li>Optionally suppress exceptions on training flow (<code>122a055</code>)</li> <li>Separate limits for dataset/surface loading (<code>4754d72</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v301-2021-07-10","title":"v3.0.1 (2021-07-10)","text":""},{"location":"CHANGELOG/#fix_18","title":"Fix","text":"<ul> <li>Overwrite dataset transforms if provided (<code>ed9dc7b</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v300-2021-07-10","title":"v3.0.0 (2021-07-10)","text":""},{"location":"CHANGELOG/#feature_9","title":"Feature","text":"<ul> <li>Notify on flow completion (via email) (<code>38fe3a2</code>)</li> </ul>"},{"location":"CHANGELOG/#breaking_1","title":"Breaking","text":"<ul> <li>notify on flow completion (via email) (<code>38fe3a2</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v220-2021-07-08","title":"v2.2.0 (2021-07-08)","text":""},{"location":"CHANGELOG/#feature_10","title":"Feature","text":"<ul> <li>Run the flow over multiple datasets (<code>d01651d</code>)</li> <li>Save training flow outputs to Google Drive by default (<code>1032892</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v210-2021-07-01","title":"v2.1.0 (2021-07-01)","text":""},{"location":"CHANGELOG/#feature_11","title":"Feature","text":"<ul> <li>Save images on flow exit (<code>83127d9</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v200-2021-07-01","title":"v2.0.0 (2021-07-01)","text":""},{"location":"CHANGELOG/#feature_12","title":"Feature","text":"<ul> <li>Enable gradient clipping (<code>14dc13f</code>)</li> </ul>"},{"location":"CHANGELOG/#breaking_2","title":"Breaking","text":"<ul> <li>convert <code>TrainingManager.__call__</code> to iterator (<code>04b18c9</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v152-2021-06-29","title":"v1.5.2 (2021-06-29)","text":""},{"location":"CHANGELOG/#fix_19","title":"Fix","text":"<ul> <li>Wrong path when invoking <code>pip</code> (<code>59cb5e3</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v151-2021-06-29","title":"v1.5.1 (2021-06-29)","text":""},{"location":"CHANGELOG/#fix_20","title":"Fix","text":"<ul> <li>Criterion and content loss weights add up to 1 (<code>2447088</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v150-2021-06-28","title":"v1.5.0 (2021-06-28)","text":""},{"location":"CHANGELOG/#feature_13","title":"Feature","text":"<ul> <li>Add title to per epoch animation (<code>52b4bc3</code>)</li> <li>Cache content loss(es) (<code>b5c9fed</code>)</li> </ul>"},{"location":"CHANGELOG/#fix_21","title":"Fix","text":"<ul> <li>Check instance class when loading <code>from_pickle</code> (<code>0dd3c8d</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v140-2021-06-27","title":"v1.4.0 (2021-06-27)","text":""},{"location":"CHANGELOG/#feature_14","title":"Feature","text":"<ul> <li>Store/load dataset to/from <code>.pt</code> file (<code>4b17918</code>)</li> <li>Save per epoch animation(s) (<code>dedc063</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v130-2021-06-24","title":"v1.3.0 (2021-06-24)","text":""},{"location":"CHANGELOG/#feature_15","title":"Feature","text":"<ul> <li>Configure logging level via <code>export</code> (<code>312f175</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v120-2021-06-23","title":"v1.2.0 (2021-06-23)","text":""},{"location":"CHANGELOG/#feature_16","title":"Feature","text":"<ul> <li>Per epoch surface batch animation (<code>448d3dc</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v110-2021-06-20","title":"v1.1.0 (2021-06-20)","text":""},{"location":"CHANGELOG/#feature_17","title":"Feature","text":"<ul> <li>Add parallel hpg content loss (<code>250e297</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v101-2021-06-20","title":"v1.0.1 (2021-06-20)","text":""},{"location":"CHANGELOG/#fix_22","title":"Fix","text":"<ul> <li>Removed <code>src</code> import(s) prefix (<code>cc0c918</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v100-2021-06-20","title":"v1.0.0 (2021-06-20)","text":""},{"location":"CHANGELOG/#fix_23","title":"Fix","text":"<ul> <li>Set python minimum version to 3.7 (<code>d81db21</code>)</li> </ul>"},{"location":"CHANGELOG/#breaking_3","title":"Breaking","text":"<ul> <li>set python minimum version to 3.7 (<code>d81db21</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CHANGELOG/#v020-2021-06-19","title":"v0.2.0 (2021-06-19)","text":""},{"location":"CHANGELOG/#feature_18","title":"Feature","text":"<ul> <li>Convert to library (<code>7aee276</code>)</li> <li>Add <code>picke</code>-ing (<code>3f9d302</code>)</li> <li>Added different flavors of content losses (<code>721c529</code>)</li> <li>Added CLI (<code>3cfd8d9</code>)</li> <li>Add <code>statistics</code> logging (<code>d7d763b</code>)</li> <li>Add timing (<code>9bfb1d6</code>)</li> <li>Add pretrained HPG2D playground (<code>6289c8b</code>)</li> </ul>"},{"location":"CHANGELOG/#fix_24","title":"Fix","text":"<ul> <li>Initial release (<code>7995a9f</code>)</li> <li>Initial version (<code>b3d7a3e</code>)</li> <li>Sync <code>py</code> and <code>ipynb</code> versions (<code>6092641</code>)</li> </ul> <p>See all commits in this version</p>"},{"location":"CODE_OF_CONDUCT/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"CODE_OF_CONDUCT/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"CODE_OF_CONDUCT/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or   advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic   address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"CODE_OF_CONDUCT/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"CODE_OF_CONDUCT/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all project spaces, and it also applies when an individual is representing the project or its community in public spaces. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p>"},{"location":"CODE_OF_CONDUCT/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting one of the project maintainers listed below. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.</p> <p>Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.</p>"},{"location":"CODE_OF_CONDUCT/#project-maintainers","title":"Project Maintainers","text":"<ul> <li>Vasilis Sioros &lt;billsioros97@gmail.com&gt;</li> </ul>"},{"location":"CODE_OF_CONDUCT/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html</p> <p>For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq</p>"},{"location":"CONTRIBUTING/","title":"Contributing","text":"<p>Hello and thank you for considering contributing to RoughGAN!</p> <p>Reading and following these guidelines will help us make the contribution process easy and effective for everyone involved.</p> <p>This project follows the all-contributors specification. You can read more here.</p>"},{"location":"CONTRIBUTING/#code-of-conduct","title":"Code of Conduct","text":"<p>By participating and contributing to this project, you agree to uphold our Code of Conduct.</p>"},{"location":"CONTRIBUTING/#getting-help","title":"Getting Help","text":"<p>In case all you need is an answer to a question, please refrain from opening an issue and instead visit the project's discussion page.</p>"},{"location":"CONTRIBUTING/#getting-started","title":"Getting Started","text":"<p>Contributions are made to this repository via Issues and Pull Requests (PRs). A few general guidelines that cover both:</p> <ul> <li>Search for existing Issues and PRs before creating your own.</li> <li>We work hard to make sure issues are handled in a timely manner but, depending on the impact, it could take a while to investigate the root cause. A friendly ping in the comment thread to the submitter or a contributor can help draw attention if your issue is blocking.</li> </ul>"},{"location":"CONTRIBUTING/#issues","title":"Issues","text":"<p>Issues should be used to report problems with the library or request a new feature or documentation change. When you create a new Issue, a template will be loaded that will guide you through collecting and providing the required information.</p> <p>If you find an Issue that addresses the problem you're having, please add your own reproduction information to the existing issue rather than creating a new one. Adding a reaction can also help in indicating to our maintainers that a particular problem is affecting more than just the reporter.</p>"},{"location":"CONTRIBUTING/#pull-requests","title":"Pull Requests","text":"<p>PRs can be a quick way to get your fix or improvement slated for the next release. In general, PRs should:</p> <ul> <li>Only fix/add the functionality in question OR address wide-spread whitespace/style issues, not both.</li> <li>Address a single concern in the least number of changed lines as possible.</li> <li>Be accompanied by a complete Pull Request template (loaded automatically when a PR is created).</li> <li>Add unit or integration tests for added or changed functionality.</li> <li>Any code related changes should be accompanied by corresponding changes to the project's documentation.</li> <li>If your pull request introduces a new feature, the corresponding <code>README</code> section must be updated to reflect this.</li> <li>Write clear, concise commit message(s) using the Conventional Commits format. Why?</li> <li>This project only accepts pull requests related to open issues. In case there is no relevant open issue, feel free to create one.</li> </ul> <p>For changes that address core functionality or would require breaking changes (e.g. a major release), it's best to open an Issue to discuss your proposal first. This is not required but can save time creating and reviewing changes.</p> <p>In general, we follow the \"fork-and-pull\" Git workflow</p> <ol> <li>Fork the repository to your own Github account</li> <li>Clone the project to your machine</li> <li>Create a branch locally with a succinct but descriptive name</li> <li>Commit changes to the branch</li> <li>Push changes to your fork</li> <li>Open a PR in our repository and follow the PR template so that we can efficiently review the changes</li> </ol>"},{"location":"CONTRIBUTING/#setting-up-a-local-development-environment","title":"Setting up a local development environment","text":"<p>The following sections assume that you have already locally cloned the repository.</p>"},{"location":"CONTRIBUTING/#installing-poetry","title":"Installing Poetry","text":"<p>The RoughGAN project utilizes the Poetry Python package manager. Having installed Poetry in the global namespace you may now run <code>poetry shell</code> to create a brand new virtual environment and <code>poetry install</code>, in order to install the project's dependencies (development dependencies as well).</p>"},{"location":"CONTRIBUTING/#installing-pre-commit-hooks","title":"Installing pre-commit hooks","text":"<p>The project utilizes the pre-commit framework. Having created a virtual environment and installed the required dependencies, you may run <code>pre-commit install --install-hooks</code> to install the git hook scripts.</p>"},{"location":"CONTRIBUTING/#testing-via-pytest","title":"Testing via <code>pytest</code>","text":"<p>We are using pytest to automate testing on multiple environments.</p> <p>The test suite can be run using <code>poetry run poe test</code>.</p>"},{"location":"CONTRIBUTING/#optional-installing-pyenv","title":"(Optional) Installing pyenv","text":"<p>pyenv is used, in the context of the cookiecutter-pypackage project, in order to determine the project's compatibility with various versions of Python. Installing <code>pyenv</code> is not strictly required, but it is recommended.</p> <p>Having installed <code>pyenv</code> in the global namespace, you may now run the following snippet, in order to install Python 3.7, 3.8 and 3.9, which, at the time of writing this document, are the only Python versions, supported by cookiecutter-pypackage.</p> <pre><code>pyenv install 3.7.10 3.8.9 3.9.4\npyenv local 3.7.10 3.8.9 3.9.4\n</code></pre> <p>Feel free to read more about using <code>pyenv</code>, in the context of <code>poetry</code>, here.</p>"},{"location":"CONTRIBUTING/#performing-development-operations-via-poethepoet","title":"Performing development operations via <code>poethepoet</code>","text":"<p>We are using poethepoet, to perform various development oriented tasks.</p> <p>Formatting, type-checking, running the test suite, as well as a few other operations, can be performed by running <code>poe &lt;task&gt;</code>. Please run <code>poe --help</code> (or <code>poetry run poe --help</code>), to list all available operations.</p>"},{"location":"CONTRIBUTING/#documenting-your-changes","title":"Documenting your changes","text":"<p>RoughGAN utilizes MkDocs to build and deploy its documentation to GitHub Pages. The documentation is auto-generated from the python docstrings throughout the source code. As a result, any code related change should be accompanied by a corresponding change to the method's / class's docstring.</p> <p>Having made your changes, please run <code>poe docs</code> and make sure that no error is being raised on build time. Afterwards, open <code>http://localhost:8000/</code> in your browser of choice and make sure that the documentation renders correctly.</p>"},{"location":"CONTRIBUTING/#writing-your-commit-message","title":"Writing your commit message","text":"<p>The project's version number and Changelog, depend on a consistent commit history. As a result, your commit message's format is extremely important. Before opening a pull request, please make sure that your commits strictly follow the Conventional Commits format].</p>"},{"location":"CONTRIBUTING/#creating-a-pull-request","title":"Creating a pull request","text":"<p>Make sure you review our Pull Request Guidelines, before initiating a PR.</p>"},{"location":"LICENSE/","title":"License","text":"<p>MIT License</p> <p>Copyright \u00a9 2023-2023 Vasilis Sioros (billsioros)</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"src/roughgan/","title":"Example","text":"<p>First of all we need to take care of a few prerequisites, most notably:</p> <ul> <li>Install the various pip modules that we will be using.</li> <li>Install some linux specific dependencies of our content loss.</li> <li>Initialize the Random Number Generator(s), so that our experiments can be replicated.</li> <li>Determine:<ul> <li>The current working directory, as it's going to be used to reference various files such as the dataset, our model checkpoints e.t.c</li> <li>The available hardware backend. GPU utilization is preferable, as it results in higher complition time.</li> </ul> </li> <li><code>(Optionally)</code> Mount Google Drive, where we can load our dataset from.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\n\nBASE_DIR = Path.cwd()\n</pre> from pathlib import Path  BASE_DIR = Path.cwd() In\u00a0[\u00a0]: Copied! <pre>GDRIVE_DIR = BASE_DIR / \"drive\"\n\ntry:\n    from google.colab import drive\n\n    drive.mount(f\"{GDRIVE_DIR}\")\nexcept ImportError:\n    pass\n</pre> GDRIVE_DIR = BASE_DIR / \"drive\"  try:     from google.colab import drive      drive.mount(f\"{GDRIVE_DIR}\") except ImportError:     pass In\u00a0[\u00a0]: Copied! <pre>SECRETS_DIR = GDRIVE_DIR / \"MyDrive\" / \"Secrets\"\n\nif GDRIVE_DIR.is_dir():\n    THESIS_DIR = GDRIVE_DIR / \"MyDrive\" / \"Thesis\"\nelse:\n    THESIS_DIR = BASE_DIR\n\nOUTPUT_DIR = THESIS_DIR / \"Output\"\n\nif THESIS_DIR.is_dir():\n    DATASET_DIR = THESIS_DIR / \"Datasets\"\nelse:\n    DATASET_DIR = BASE_DIR / \"Datasets\"\n</pre> SECRETS_DIR = GDRIVE_DIR / \"MyDrive\" / \"Secrets\"  if GDRIVE_DIR.is_dir():     THESIS_DIR = GDRIVE_DIR / \"MyDrive\" / \"Thesis\" else:     THESIS_DIR = BASE_DIR  OUTPUT_DIR = THESIS_DIR / \"Output\"  if THESIS_DIR.is_dir():     DATASET_DIR = THESIS_DIR / \"Datasets\" else:     DATASET_DIR = BASE_DIR / \"Datasets\" In\u00a0[\u00a0]: Copied! <pre>import os\n\nLOGGING_LEVEL = os.environ.get(\"LOGGING_LEVEL\", \"CRITICAL\").upper()\n\nLOGGING_CONFIG = {\n    \"version\": 1,\n    \"disable_existing_loggers\": False,\n    \"formatters\": {\"standard\": {\"format\": \"[%(asctime)s] %(levelname)s:%(name)s: %(message)s\"}},\n    \"handlers\": {\n        \"default\": {\n            \"level\": LOGGING_LEVEL,\n            \"formatter\": \"standard\",\n            \"class\": \"logging.StreamHandler\",\n        },\n        \"file\": {\n            \"level\": LOGGING_LEVEL,\n            \"formatter\": \"standard\",\n            \"class\": \"logging.FileHandler\",\n        },\n    },\n    \"loggers\": {\"\": {\"handlers\": [\"default\", \"file\"], \"level\": LOGGING_LEVEL}},\n}\n</pre> import os  LOGGING_LEVEL = os.environ.get(\"LOGGING_LEVEL\", \"CRITICAL\").upper()  LOGGING_CONFIG = {     \"version\": 1,     \"disable_existing_loggers\": False,     \"formatters\": {\"standard\": {\"format\": \"[%(asctime)s] %(levelname)s:%(name)s: %(message)s\"}},     \"handlers\": {         \"default\": {             \"level\": LOGGING_LEVEL,             \"formatter\": \"standard\",             \"class\": \"logging.StreamHandler\",         },         \"file\": {             \"level\": LOGGING_LEVEL,             \"formatter\": \"standard\",             \"class\": \"logging.FileHandler\",         },     },     \"loggers\": {\"\": {\"handlers\": [\"default\", \"file\"], \"level\": LOGGING_LEVEL}}, } <p>The aforementioned packages are required by PyINSECT and more specifically its graph plotting methods.</p> In\u00a0[\u00a0]: Copied! <pre>!sudo apt-get install graphviz libgraphviz-dev 1&gt; /dev/null\n</pre> !sudo apt-get install graphviz libgraphviz-dev 1&gt; /dev/null <ul> <li>torch is our machine learning framework of choice.</li> <li>numpy, sympy and scipy are used to in the context of nanorough surface generation.</li> <li>plotly (which requires pandas) as well as matplotlib are used in order to plot various graphs.</li> </ul> In\u00a0[\u00a0]: Copied! <pre>WHEEL_VERSION = \"3.0.1\"\nWHEEL_FILE = \"roughgan-%s-py3-none-any.whl\" % (WHEEL_VERSION,)\nWHEEL_PATH = THESIS_DIR / \"Binaries\" / WHEEL_FILE\n</pre> WHEEL_VERSION = \"3.0.1\" WHEEL_FILE = \"roughgan-%s-py3-none-any.whl\" % (WHEEL_VERSION,) WHEEL_PATH = THESIS_DIR / \"Binaries\" / WHEEL_FILE In\u00a0[\u00a0]: Copied! <pre>import os\nimport random\n</pre> import os import random In\u00a0[\u00a0]: Copied! <pre>import subprocess\nimport sys\n\nimport numpy as np\n\npip_freeze_output = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"freeze\"]).decode()\n\nif \"roughgan\" not in pip_freeze_output:\n    if WHEEL_PATH.is_file():\n        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", WHEEL_PATH])\n    else:\n        raise FileNotFoundError(WHEEL_PATH)\n</pre> import subprocess import sys  import numpy as np  pip_freeze_output = subprocess.check_output([sys.executable, \"-m\", \"pip\", \"freeze\"]).decode()  if \"roughgan\" not in pip_freeze_output:     if WHEEL_PATH.is_file():         subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", WHEEL_PATH])     else:         raise FileNotFoundError(WHEEL_PATH) In\u00a0[\u00a0]: Copied! <pre>import torch\n\nSEED = 1234\n\nif SEED is not None:\n    np.random.seed(SEED)\n    random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.deterministic = True\n    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n</pre> import torch  SEED = 1234  if SEED is not None:     np.random.seed(SEED)     random.seed(SEED)     torch.manual_seed(SEED)     torch.cuda.manual_seed(SEED)     torch.backends.cudnn.deterministic = True     os.environ[\"PYTHONHASHSEED\"] = str(SEED) <p>By default, we are going to be utilizing the available CPU backend, if no GPU is available.</p> In\u00a0[\u00a0]: Copied! <pre>device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n</pre> device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") In\u00a0[\u00a0]: Copied! <pre>from datetime import datetime\n\nfrom roughgan.shared.notifiers import EndOfTrainingNotifier\n\ntraining_callback = None\nif SECRETS_DIR.is_dir():\n    notifier = EndOfTrainingNotifier.from_json(SECRETS_DIR / \"credentials.json\")\n\n    timestamp = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S.%f\")\n\n    def training_callback(log_file=None, **context):\n        notifier(\n            (\"Vasilis Sioros\", \"billsioros97@gmail.com\"),\n            log_file=log_file,\n            dataset=context[\"dataset\"],\n            generator=context[\"generator\"],\n            discriminator=context[\"discriminator\"],\n            elapsed_time=context[\"elapsed_time\"],\n            succeeded=context[\"succeeded\"],\n            identifier=timestamp,\n        )\n</pre> from datetime import datetime  from roughgan.shared.notifiers import EndOfTrainingNotifier  training_callback = None if SECRETS_DIR.is_dir():     notifier = EndOfTrainingNotifier.from_json(SECRETS_DIR / \"credentials.json\")      timestamp = datetime.now().strftime(\"%Y/%m/%d %H:%M:%S.%f\")      def training_callback(log_file=None, **context):         notifier(             (\"Vasilis Sioros\", \"billsioros97@gmail.com\"),             log_file=log_file,             dataset=context[\"dataset\"],             generator=context[\"generator\"],             discriminator=context[\"discriminator\"],             elapsed_time=context[\"elapsed_time\"],             succeeded=context[\"succeeded\"],             identifier=timestamp,         ) In\u00a0[\u00a0]: Copied! <pre>def logging_callback(config, logging_dir):\n    level = config.handlers.file.level.lower()\n\n    config.handlers.file.filename = logging_dir / f\"{level}.log\"\n\n    return config\n</pre> def logging_callback(config, logging_dir):     level = config.handlers.file.level.lower()      config.handlers.file.filename = logging_dir / f\"{level}.log\"      return config In\u00a0[\u00a0]: Copied! <pre>from roughgan.models import PerceptronGenerator\n\n\ndef get_generator():\n    return PerceptronGenerator.from_device(device)\n</pre> from roughgan.models import PerceptronGenerator   def get_generator():     return PerceptronGenerator.from_device(device) In\u00a0[\u00a0]: Copied! <pre>from roughgan.models import PerceptronDiscriminator\n\n\ndef get_discriminator(generator):\n    return PerceptronDiscriminator.from_generator(generator)\n</pre> from roughgan.models import PerceptronDiscriminator   def get_discriminator(generator):     return PerceptronDiscriminator.from_generator(generator) In\u00a0[\u00a0]: Copied! <pre>from torch.nn import BCELoss\n\ncriterion = BCELoss().to(device)\n</pre> from torch.nn import BCELoss  criterion = BCELoss().to(device) In\u00a0[\u00a0]: Copied! <pre>import functools\n\nfrom torch.optim import Adam\n\nfrom roughgan.content.loss import NGramGraphContentLoss\nfrom roughgan.data.loaders import load_multiple_datasets_from_pt\nfrom roughgan.data.transforms import To, View\nfrom roughgan.training.epoch import per_epoch\nfrom roughgan.training.flow import TrainingFlow\n\ntraining_flow = TrainingFlow(\n    output_dir=OUTPUT_DIR,\n    logging={\"config\": LOGGING_CONFIG, \"callback\": logging_callback},\n    training={\n        \"manager\": {\n            \"benchmark\": True,\n            # Uncomment if you want to enable checkpointing\n            # \"checkpoint\": {\"multiple\": True},\n            \"train_epoch\": per_epoch,\n            \"log_every_n\": 10,\n            \"criterion\": {\"instance\": criterion},\n            \"n_epochs\": 10,\n            \"train_ratio\": 0.8,\n            \"optimizer\": {\n                \"type\": Adam,\n                \"params\": {\"lr\": 0.1, \"weight_decay\": 0},\n            },\n            \"dataloader\": {\n                \"batch_size\": 256,\n                \"shuffle\": True,\n                \"num_workers\": 0,\n            },\n        },\n        \"callbacks\": [\n            training_callback,\n        ],\n    },\n    content_loss={\n        \"type\": NGramGraphContentLoss,\n        # Uncomment if you want to enable checkpointing\n        # \"cache\": \"n_gram_graph_content_loss.pkl\",\n    },\n    data={\n        \"loader\": functools.partial(\n            load_multiple_datasets_from_pt,\n            DATASET_DIR,\n            transforms=[To(device), View(1, 128, 128)],\n            limit=(2, 10),\n        )\n    },\n    animation={\n        \"indices\": [\n            0,\n        ],\n        \"save_path\": \"perceptron_per_epoch_animation.mp4\",\n    },\n    plot={\n        \"grayscale\": {\"limit\": 10, \"save_path_fmt\": \"grayscale/%s_%02d.png\"},\n        \"surface\": {\"limit\": 10, \"save_path_fmt\": \"surface/%s_%02d.png\"},\n        \"against\": {\"save_path_fmt\": \"against_%s.png\"},\n    },\n    suppress_exceptions=False,\n)\n</pre> import functools  from torch.optim import Adam  from roughgan.content.loss import NGramGraphContentLoss from roughgan.data.loaders import load_multiple_datasets_from_pt from roughgan.data.transforms import To, View from roughgan.training.epoch import per_epoch from roughgan.training.flow import TrainingFlow  training_flow = TrainingFlow(     output_dir=OUTPUT_DIR,     logging={\"config\": LOGGING_CONFIG, \"callback\": logging_callback},     training={         \"manager\": {             \"benchmark\": True,             # Uncomment if you want to enable checkpointing             # \"checkpoint\": {\"multiple\": True},             \"train_epoch\": per_epoch,             \"log_every_n\": 10,             \"criterion\": {\"instance\": criterion},             \"n_epochs\": 10,             \"train_ratio\": 0.8,             \"optimizer\": {                 \"type\": Adam,                 \"params\": {\"lr\": 0.1, \"weight_decay\": 0},             },             \"dataloader\": {                 \"batch_size\": 256,                 \"shuffle\": True,                 \"num_workers\": 0,             },         },         \"callbacks\": [             training_callback,         ],     },     content_loss={         \"type\": NGramGraphContentLoss,         # Uncomment if you want to enable checkpointing         # \"cache\": \"n_gram_graph_content_loss.pkl\",     },     data={         \"loader\": functools.partial(             load_multiple_datasets_from_pt,             DATASET_DIR,             transforms=[To(device), View(1, 128, 128)],             limit=(2, 10),         )     },     animation={         \"indices\": [             0,         ],         \"save_path\": \"perceptron_per_epoch_animation.mp4\",     },     plot={         \"grayscale\": {\"limit\": 10, \"save_path_fmt\": \"grayscale/%s_%02d.png\"},         \"surface\": {\"limit\": 10, \"save_path_fmt\": \"surface/%s_%02d.png\"},         \"against\": {\"save_path_fmt\": \"against_%s.png\"},     },     suppress_exceptions=False, ) In\u00a0[\u00a0]: Copied! <pre>training_flow(get_generator, get_discriminator)\n</pre> training_flow(get_generator, get_discriminator) In\u00a0[\u00a0]: Copied! <pre>from roughgan.models import CNNGenerator\n\n\ndef get_generator():\n    return CNNGenerator.from_device(device)\n</pre> from roughgan.models import CNNGenerator   def get_generator():     return CNNGenerator.from_device(device) In\u00a0[\u00a0]: Copied! <pre>from roughgan.models import CNNDiscriminator\n\n\ndef get_discriminator(generator):\n    return CNNDiscriminator.from_generator(generator)\n</pre> from roughgan.models import CNNDiscriminator   def get_discriminator(generator):     return CNNDiscriminator.from_generator(generator) In\u00a0[\u00a0]: Copied! <pre>from torch.nn import BCELoss\n\ncriterion = BCELoss().to(device)\n</pre> from torch.nn import BCELoss  criterion = BCELoss().to(device) In\u00a0[\u00a0]: Copied! <pre>import functools\n\nfrom torch.optim import Adam\n\nfrom roughgan.data.transforms import To, View\nfrom roughgan.training.epoch import per_epoch\n\ntraining_flow = TrainingFlow(\n    output_dir=OUTPUT_DIR,\n    logging={\"config\": LOGGING_CONFIG, \"callback\": logging_callback},\n    training={\n        \"manager\": {\n            \"benchmark\": True,\n            # Uncomment if you want to enable checkpointing\n            # \"checkpoint\": {\"multiple\": True},\n            \"train_epoch\": per_epoch,\n            \"log_every_n\": 10,\n            \"criterion\": {\"instance\": criterion},\n            \"n_epochs\": 10,\n            \"train_ratio\": 0.8,\n            \"optimizer\": {\n                \"type\": Adam,\n                \"params\": {\"lr\": 0.0002, \"betas\": (0.5, 0.999)},\n            },\n            \"dataloader\": {\n                \"batch_size\": 256,\n                \"shuffle\": True,\n                \"num_workers\": 0,\n            },\n        },\n        \"callbacks\": [\n            training_callback,\n        ],\n    },\n    content_loss={\n        \"type\": NGramGraphContentLoss,\n        # Uncomment if you want to enable checkpointing\n        # \"cache\": \"n_gram_graph_content_loss.pkl\",\n    },\n    data={\n        \"loader\": functools.partial(\n            load_multiple_datasets_from_pt,\n            DATASET_DIR,\n            transforms=[To(device), View(1, 128, 128)],\n            limit=(2, 10),\n        )\n    },\n    animation={\n        \"indices\": [\n            0,\n        ],\n        \"save_path\": \"cnn_per_epoch_animation.mp4\",\n    },\n    plot={\n        \"grayscale\": {\"limit\": 10, \"save_path_fmt\": \"grayscale/%s_%02d.png\"},\n        \"surface\": {\"limit\": 10, \"save_path_fmt\": \"surface/%s_%02d.png\"},\n        \"against\": {\"save_path_fmt\": \"against_%s.png\"},\n    },\n    suppress_exceptions=False,\n)\n</pre> import functools  from torch.optim import Adam  from roughgan.data.transforms import To, View from roughgan.training.epoch import per_epoch  training_flow = TrainingFlow(     output_dir=OUTPUT_DIR,     logging={\"config\": LOGGING_CONFIG, \"callback\": logging_callback},     training={         \"manager\": {             \"benchmark\": True,             # Uncomment if you want to enable checkpointing             # \"checkpoint\": {\"multiple\": True},             \"train_epoch\": per_epoch,             \"log_every_n\": 10,             \"criterion\": {\"instance\": criterion},             \"n_epochs\": 10,             \"train_ratio\": 0.8,             \"optimizer\": {                 \"type\": Adam,                 \"params\": {\"lr\": 0.0002, \"betas\": (0.5, 0.999)},             },             \"dataloader\": {                 \"batch_size\": 256,                 \"shuffle\": True,                 \"num_workers\": 0,             },         },         \"callbacks\": [             training_callback,         ],     },     content_loss={         \"type\": NGramGraphContentLoss,         # Uncomment if you want to enable checkpointing         # \"cache\": \"n_gram_graph_content_loss.pkl\",     },     data={         \"loader\": functools.partial(             load_multiple_datasets_from_pt,             DATASET_DIR,             transforms=[To(device), View(1, 128, 128)],             limit=(2, 10),         )     },     animation={         \"indices\": [             0,         ],         \"save_path\": \"cnn_per_epoch_animation.mp4\",     },     plot={         \"grayscale\": {\"limit\": 10, \"save_path_fmt\": \"grayscale/%s_%02d.png\"},         \"surface\": {\"limit\": 10, \"save_path_fmt\": \"surface/%s_%02d.png\"},         \"against\": {\"save_path_fmt\": \"against_%s.png\"},     },     suppress_exceptions=False, ) In\u00a0[\u00a0]: Copied! <pre>training_flow(get_generator, get_discriminator)\n</pre> training_flow(get_generator, get_discriminator) In\u00a0[\u00a0]: Copied! <pre>try:\n    from google.colab import drive\n\n    drive.flush_and_unmount()\nexcept ImportError:\n    pass\n</pre> try:     from google.colab import drive      drive.flush_and_unmount() except ImportError:     pass"},{"location":"src/roughgan/#prerequisites","title":"\u2714\ufe0f Prerequisites\u00b6","text":""},{"location":"src/roughgan/#determining-the-current-working-directory","title":"Determining the Current Working Directory\u00b6","text":""},{"location":"src/roughgan/#mounting-google-drive","title":"Mounting Google Drive\u00b6","text":""},{"location":"src/roughgan/#configuring-our-loggers","title":"Configuring our Loggers\u00b6","text":""},{"location":"src/roughgan/#installing-graphviz-libgraphviz-dev","title":"Installing graphviz &amp; libgraphviz-dev\u00b6","text":""},{"location":"src/roughgan/#installing-the-required-pip-modules","title":"Installing the required <code>pip</code> modules\u00b6","text":""},{"location":"src/roughgan/#initializing-aka-seeding-the-random-number-generators","title":"Initializing (a.k.a <code>Seeding</code>) the Random Number Generator(s)\u00b6","text":""},{"location":"src/roughgan/#determining-available-backend","title":"Determining available backend\u00b6","text":""},{"location":"src/roughgan/#setting-up-our-callbacks","title":"Setting up our callbacks\u00b6","text":""},{"location":"src/roughgan/#end-of-training-callback","title":"End-of-training callback\u00b6","text":""},{"location":"src/roughgan/#logging-initialization-callback","title":"Logging initialization callback\u00b6","text":""},{"location":"src/roughgan/#a-naive-approach","title":"\ud83d\ude43 A naive-approach\u00b6","text":""},{"location":"src/roughgan/#defining-the-generator-and-the-discriminator-instantiation-callbacks","title":"Defining the Generator and the Discriminator instantiation callbacks\u00b6","text":""},{"location":"src/roughgan/#training","title":"Training\u00b6","text":""},{"location":"src/roughgan/#a-cnn-based-approach","title":"\ud83d\ude0e A CNN based approach\u00b6","text":""},{"location":"src/roughgan/#instantiating-the-generator-and-the-discriminator-networks","title":"Instantiating the Generator and the Discriminator Networks\u00b6","text":""},{"location":"src/roughgan/#training","title":"Training\u00b6","text":""},{"location":"src/roughgan/#dismounting-google-drive-and-persisting-any-changes-made","title":"\ud83d\udc4b Dismounting Google Drive and persisting any changes made\u00b6","text":""},{"location":"src/cli/benchmark/","title":"<code>benchmark</code> CLI Reference","text":""},{"location":"src/cli/benchmark/#benchmark","title":"benchmark","text":"<p>Usage:</p> <pre><code>benchmark [OPTIONS]\n</code></pre> <p>Options:</p> <pre><code>  -s, --similarity [A2G|NGG|HPG|FHS]\n                                  The content similarity metric that you would\n                                  like to benchmark\n  --help                          Show this message and exit.\n</code></pre>"}]}